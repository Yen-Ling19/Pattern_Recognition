{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 樣型識別 CH09-2\n",
    "\n",
    "B0729003 何妍霖 資工四"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Modern convnet architecture patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modularity, hierarchy, and reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Residual block where the number of filters changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Case where target block includes a max pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 32, 32, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 32, 32)   896         ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 32, 32, 32)   9248        ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 16, 16, 32)   128         ['rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 16, 32)   0           ['max_pooling2d_7[0][0]',        \n",
      "                                                                  'conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 16, 16, 64)   18496       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 8, 8, 64)     2112        ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 8, 8, 64)     0           ['max_pooling2d_8[0][0]',        \n",
      "                                                                  'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 8, 8, 128)    73856       ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 8, 8, 128)    8320        ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 8, 8, 128)    0           ['conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['add_14[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297,697\n",
      "Trainable params: 297,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "def residual_block(x, filters, pooling=False):\n",
    "    residual = x\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    if pooling:\n",
    "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "    elif filters != residual.shape[-1]:\n",
    "        residual = layers.Conv2D(filters, 1)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "    return x\n",
    "\n",
    "x = residual_block(x, filters=32, pooling=True)\n",
    "x = residual_block(x, filters=64, pooling=True)\n",
    "x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Depthwise separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Putting it together: A mini Xception-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c dogs-vs-cats\n",
    "# !unzip -qq train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# original_dir = pathlib.Path(\"train\")\n",
    "# new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "original_dir = pathlib.Path(r'C:\\Users\\csie\\Desktop\\ML\\CH09\\CH09-2\\train')\n",
    "new_base_dir = pathlib.Path(r'C:\\Users\\csie\\Desktop\\ML\\CH09\\CH09-2\\cats_vs_dogs_small')\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "# make_subset(\"train\", start_index=0, end_index=1000)\n",
    "# make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "# make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(\n",
    "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 28s 328ms/step - loss: 0.7066 - accuracy: 0.5615 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.6659 - accuracy: 0.5805 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.6454 - accuracy: 0.6450 - val_loss: 0.6924 - val_accuracy: 0.5190\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.6251 - accuracy: 0.6485 - val_loss: 0.6982 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.6102 - accuracy: 0.6630 - val_loss: 0.7111 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.5932 - accuracy: 0.6925 - val_loss: 0.7318 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.5680 - accuracy: 0.7090 - val_loss: 0.8221 - val_accuracy: 0.5080\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.5558 - accuracy: 0.7230 - val_loss: 0.6614 - val_accuracy: 0.6030\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.5431 - accuracy: 0.7400 - val_loss: 0.7182 - val_accuracy: 0.5880\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.5241 - accuracy: 0.7480 - val_loss: 0.8760 - val_accuracy: 0.5450\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.5104 - accuracy: 0.7515 - val_loss: 0.6632 - val_accuracy: 0.6520\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.4879 - accuracy: 0.7725 - val_loss: 0.5244 - val_accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.4831 - accuracy: 0.7725 - val_loss: 0.6758 - val_accuracy: 0.6610\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.4764 - accuracy: 0.7785 - val_loss: 0.5072 - val_accuracy: 0.7440\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.4550 - accuracy: 0.7850 - val_loss: 0.5317 - val_accuracy: 0.7600\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.4613 - accuracy: 0.7870 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.4494 - accuracy: 0.7950 - val_loss: 0.5464 - val_accuracy: 0.7270\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.4256 - accuracy: 0.8025 - val_loss: 0.8116 - val_accuracy: 0.5920\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.4368 - accuracy: 0.7980 - val_loss: 0.6525 - val_accuracy: 0.7260\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.4052 - accuracy: 0.8215 - val_loss: 0.5701 - val_accuracy: 0.7470\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.4039 - accuracy: 0.8220 - val_loss: 0.4895 - val_accuracy: 0.7640\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.3886 - accuracy: 0.8230 - val_loss: 0.5006 - val_accuracy: 0.7560\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.3854 - accuracy: 0.8225 - val_loss: 1.7809 - val_accuracy: 0.5950\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.3900 - accuracy: 0.8300 - val_loss: 0.4615 - val_accuracy: 0.7780\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3654 - accuracy: 0.8365 - val_loss: 0.4850 - val_accuracy: 0.7990\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3610 - accuracy: 0.8430 - val_loss: 0.5723 - val_accuracy: 0.7230\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3538 - accuracy: 0.8330 - val_loss: 0.5536 - val_accuracy: 0.7530\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3480 - accuracy: 0.8465 - val_loss: 0.5486 - val_accuracy: 0.7510\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 20s 313ms/step - loss: 0.3409 - accuracy: 0.8490 - val_loss: 0.5137 - val_accuracy: 0.7710\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3417 - accuracy: 0.8515 - val_loss: 0.5160 - val_accuracy: 0.7550\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.3225 - accuracy: 0.8620 - val_loss: 0.4125 - val_accuracy: 0.8350\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.3195 - accuracy: 0.8640 - val_loss: 0.6168 - val_accuracy: 0.7410\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.3003 - accuracy: 0.8670 - val_loss: 0.4539 - val_accuracy: 0.7910\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.2927 - accuracy: 0.8710 - val_loss: 0.4253 - val_accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.3105 - accuracy: 0.8600 - val_loss: 1.1067 - val_accuracy: 0.6170\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.3021 - accuracy: 0.8625 - val_loss: 0.4291 - val_accuracy: 0.8070\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.2779 - accuracy: 0.8875 - val_loss: 0.7272 - val_accuracy: 0.7290\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 20s 313ms/step - loss: 0.2755 - accuracy: 0.8945 - val_loss: 0.8361 - val_accuracy: 0.7120\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.2636 - accuracy: 0.8925 - val_loss: 0.5772 - val_accuracy: 0.7710\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.2738 - accuracy: 0.8815 - val_loss: 0.6318 - val_accuracy: 0.7490\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.2773 - accuracy: 0.8775 - val_loss: 0.5482 - val_accuracy: 0.7640\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.2676 - accuracy: 0.8860 - val_loss: 0.3538 - val_accuracy: 0.8490\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.2382 - accuracy: 0.8985 - val_loss: 1.7580 - val_accuracy: 0.6130\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.2507 - accuracy: 0.8935 - val_loss: 0.7059 - val_accuracy: 0.7700\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.2485 - accuracy: 0.8960 - val_loss: 0.5357 - val_accuracy: 0.8020\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.2436 - accuracy: 0.9015 - val_loss: 0.5113 - val_accuracy: 0.7940\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.2231 - accuracy: 0.9080 - val_loss: 0.4506 - val_accuracy: 0.8130\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.2239 - accuracy: 0.9015 - val_loss: 0.4574 - val_accuracy: 0.8360\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.2304 - accuracy: 0.8995 - val_loss: 0.3947 - val_accuracy: 0.8280\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.2005 - accuracy: 0.9145 - val_loss: 0.4941 - val_accuracy: 0.8070\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.2211 - accuracy: 0.9115 - val_loss: 0.5498 - val_accuracy: 0.8050\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.2081 - accuracy: 0.9185 - val_loss: 0.4769 - val_accuracy: 0.7970\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.2122 - accuracy: 0.9115 - val_loss: 0.5340 - val_accuracy: 0.8230\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.2005 - accuracy: 0.9185 - val_loss: 0.4324 - val_accuracy: 0.8490\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.1953 - accuracy: 0.9250 - val_loss: 0.3833 - val_accuracy: 0.8600\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.2095 - accuracy: 0.9140 - val_loss: 0.4853 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.1842 - accuracy: 0.9215 - val_loss: 0.4968 - val_accuracy: 0.8180\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1920 - accuracy: 0.9270 - val_loss: 0.4596 - val_accuracy: 0.8440\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1864 - accuracy: 0.9230 - val_loss: 0.5340 - val_accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1964 - accuracy: 0.9260 - val_loss: 0.4105 - val_accuracy: 0.8530\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1724 - accuracy: 0.9330 - val_loss: 1.2211 - val_accuracy: 0.7150\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.1997 - accuracy: 0.9245 - val_loss: 0.3830 - val_accuracy: 0.8530\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.1879 - accuracy: 0.9260 - val_loss: 0.5970 - val_accuracy: 0.8280\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.1508 - accuracy: 0.9435 - val_loss: 1.6022 - val_accuracy: 0.6650\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1755 - accuracy: 0.9255 - val_loss: 0.6775 - val_accuracy: 0.8080\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1707 - accuracy: 0.9335 - val_loss: 0.5337 - val_accuracy: 0.8320\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 20s 321ms/step - loss: 0.1713 - accuracy: 0.9350 - val_loss: 0.8203 - val_accuracy: 0.7550\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.1533 - accuracy: 0.9370 - val_loss: 0.3719 - val_accuracy: 0.8570\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1554 - accuracy: 0.9330 - val_loss: 0.5586 - val_accuracy: 0.8320\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.1556 - accuracy: 0.9410 - val_loss: 0.6587 - val_accuracy: 0.8150\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1523 - accuracy: 0.9370 - val_loss: 0.5598 - val_accuracy: 0.7980\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.1604 - accuracy: 0.9360 - val_loss: 0.4493 - val_accuracy: 0.8570\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.1268 - accuracy: 0.9465 - val_loss: 0.3722 - val_accuracy: 0.8730\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1470 - accuracy: 0.9420 - val_loss: 0.7712 - val_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1400 - accuracy: 0.9455 - val_loss: 0.4487 - val_accuracy: 0.8680\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1495 - accuracy: 0.9410 - val_loss: 0.4638 - val_accuracy: 0.8580\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.1395 - accuracy: 0.9400 - val_loss: 0.7915 - val_accuracy: 0.7880\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1368 - accuracy: 0.9435 - val_loss: 0.4773 - val_accuracy: 0.8480\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1351 - accuracy: 0.9430 - val_loss: 0.4562 - val_accuracy: 0.8580\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1325 - accuracy: 0.9465 - val_loss: 0.4046 - val_accuracy: 0.8480\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1311 - accuracy: 0.9530 - val_loss: 0.6150 - val_accuracy: 0.7830\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.1258 - accuracy: 0.9475 - val_loss: 0.6414 - val_accuracy: 0.8080\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1300 - accuracy: 0.9460 - val_loss: 0.4558 - val_accuracy: 0.8600\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1123 - accuracy: 0.9610 - val_loss: 0.4083 - val_accuracy: 0.8520\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1408 - accuracy: 0.9475 - val_loss: 0.4122 - val_accuracy: 0.8670\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1104 - accuracy: 0.9550 - val_loss: 0.4424 - val_accuracy: 0.8560\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.1228 - accuracy: 0.9500 - val_loss: 0.4425 - val_accuracy: 0.8600\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 20s 322ms/step - loss: 0.1188 - accuracy: 0.9525 - val_loss: 0.3731 - val_accuracy: 0.8820\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1409 - accuracy: 0.9470 - val_loss: 1.1854 - val_accuracy: 0.7580\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1188 - accuracy: 0.9545 - val_loss: 0.5760 - val_accuracy: 0.8420\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 20s 316ms/step - loss: 0.1116 - accuracy: 0.9555 - val_loss: 0.3960 - val_accuracy: 0.8900\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1399 - accuracy: 0.9425 - val_loss: 0.4915 - val_accuracy: 0.8560\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1075 - accuracy: 0.9590 - val_loss: 0.7972 - val_accuracy: 0.7880\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1215 - accuracy: 0.9535 - val_loss: 0.3421 - val_accuracy: 0.8980\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 20s 313ms/step - loss: 0.1181 - accuracy: 0.9580 - val_loss: 0.3554 - val_accuracy: 0.8940\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 20s 315ms/step - loss: 0.1023 - accuracy: 0.9620 - val_loss: 0.3449 - val_accuracy: 0.8720\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 20s 313ms/step - loss: 0.0885 - accuracy: 0.9665 - val_loss: 0.8126 - val_accuracy: 0.8170\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.1126 - accuracy: 0.9555 - val_loss: 0.6129 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.0994 - accuracy: 0.9610 - val_loss: 0.3581 - val_accuracy: 0.8820\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.0977 - accuracy: 0.9575 - val_loss: 0.4223 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter09_part02_modern-convnet-architecture-patterns.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc2d75d2bbb1ab8d2c49183bedcbafe25b599ed2fa73b8834cc66076892a6e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
